{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compute markers used for DOC-Forest recipe\n\n\nHere we compute the markers from previously computed markers as published [1].\n\nFor simplicity, we only compute scalars using a trimmed mean (80%) accross\nepochs and the mean across channels.\n\nReferences\n----------\n.. [1] Engemann D.A.*, Raimondo F.*, King JR., Rohaut B., Louppe G.,\n       Faugeras F., Annen J., Cassol H., Gosseries O., Fernandez-Slezak D.,\n       Laureys S., Naccache L., Dehaene S. and Sitt J.D. (2018).\n       Robust EEG-based cross-site and cross-protocol classification of\n       states of consciousness. Brain. doi:10.1093/brain/awy251\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Denis A. Engemann <denis.engemann@gmail.com>\n#          Federico Raimondo <federaimondo@gmail.com>\n\nimport numpy as np\nfrom scipy.stats import trim_mean\nimport os.path as op\n\nimport mne\n\nfrom nice import read_markers\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.path import Path\nfrom matplotlib.patches import PathPatch\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\nimport seaborn as sns\nsns.set_color_codes()\n\n\ndef trim_mean80(a, axis=0):  # noqa\n    return trim_mean(a, proportiontocut=.1, axis=axis)\n\n\ndef entropy(a, axis=0):  # noqa\n    return -np.nansum(a * np.log(a), axis=axis) / np.log(a.shape[axis])\n\n\nfname = 'data/JSXXX-markers.hdf5'\nif not op.exists(fname):\n    raise ValueError('Please run compute_doc_forest_markers.py example first')\n\nfc = read_markers(fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set regions of interest\n\nFor some markers we do not want to use all channels. We therefore supply\nselections of channels for some markers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scalp_roi = np.arange(224)\nnon_scalp = np.arange(224, 256)\ncnv_roi = np.array([5,  6, 13, 14, 15, 21, 22])\nmmn_roi = np.array([5,   6,   8,  13,  14,  15,  21,  22,  44,  80, 131, 185])\np3b_roi = np.array([8,  44,  80,  99, 100, 109, 118, 127, 128, 131, 185])\np3a_roi = np.array([5,   6,   8,  13,  14,  15,  21,  22,  44,  80, 131, 185])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set reduction functions\n\nWe want delineate different features from each marker. We therefore\nsummarize each marker over epochs and channels. Here we only compute the\nmean over epochs and channels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "channels_fun = np.mean  # function to summarize channels\nepochs_fun = trim_mean80  # robust mean to summarize epochs\n\n# For each class of marker we can specify how the reductions have to be\n# computed. Each class therefore gets an entry in the `reduction_params`.\n# This has to be a dictionary with the keys `reduction_func` and `picks`.\n# The first key is a list and can be read as follows: for each reduction,\n# sequentially apply `function` over `axis` and then pass the output to the\n# next step. For the first example below, we first compute the mean over\n# epochs, then the mean over channelsm, and finally, the sum over frequencies.\n# While doing so, only consider the channels in `picks`.\n# We could also specificy which epochs to use by setting `epochs`.\n# We will do this for each class of markers.\n\nreduction_params = {}\nreduction_params['PowerSpectralDensity'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels', 'function': channels_fun},\n         {'axis': 'frequency', 'function': np.sum}],\n    'picks': {\n        'epochs': None,\n        'channels': scalp_roi}}\n\nreduction_params['PowerSpectralDensity/summary_se'] = {\n    'reduction_func':\n        [{'axis': 'frequency', 'function': entropy},\n         {'axis': 'epochs', 'function': np.mean},\n         {'axis': 'channels', 'function': channels_fun}],\n    'picks': {\n        'epochs': None,\n        'channels': scalp_roi}}\n\nreduction_params['PowerSpectralDensitySummary'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels', 'function': channels_fun}],\n    'picks': {\n        'epochs': None,\n        'channels': scalp_roi}}\n\nreduction_params['PermutationEntropy'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels', 'function': channels_fun}],\n    'picks': {\n        'epochs': None,\n        'channels': scalp_roi}}\n\nreduction_params['SymbolicMutualInformation'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels_y', 'function': np.median},\n         {'axis': 'channels', 'function': channels_fun}],\n    'picks': {\n        'epochs': None,\n        'channels_y': scalp_roi,\n        'channels': scalp_roi}}\n\nreduction_params['KolmogorovComplexity'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels', 'function': channels_fun}],\n    'picks': {\n        'epochs': None,\n        'channels': scalp_roi}}\n\nreduction_params['ContingentNegativeVariation'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels', 'function': channels_fun}],\n    'picks': {\n        'epochs': None,\n        'channels': cnv_roi}}\n\nreduction_params['TimeLockedTopography'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels', 'function': channels_fun},\n         {'axis': 'times', 'function': np.mean}],\n    'picks': {\n        'epochs': None,\n        'channels': scalp_roi,\n        'times': None}}\n\nreduction_params['TimeLockedContrast'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels', 'function': channels_fun},\n         {'axis': 'times', 'function': np.mean}],\n    'picks': {\n        'epochs': None,\n        'channels': scalp_roi,\n        'times': None}}\n\nreduction_params['TimeLockedContrast/mmn'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels', 'function': channels_fun},\n         {'axis': 'times', 'function': np.mean}],\n    'picks': {\n        'epochs': None,\n        'channels': mmn_roi,\n        'times': None}}\n\nreduction_params['TimeLockedContrast/p3b'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels', 'function': channels_fun},\n         {'axis': 'times', 'function': np.mean}],\n    'picks': {\n        'epochs': None,\n        'channels': p3b_roi,\n        'times': None}}\n\nreduction_params['TimeLockedContrast/p3a'] = {\n    'reduction_func':\n        [{'axis': 'epochs', 'function': epochs_fun},\n         {'axis': 'channels', 'function': channels_fun},\n         {'axis': 'times', 'function': np.mean}],\n    'picks': {\n        'epochs': None,\n        'channels': p3a_roi,\n        'times': None}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actually compute reductions\n\nNow we can summarize the markers either into scalars (1 marker, 1 value)\nor topos (1 marker, n_channels values).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scalars = fc.reduce_to_scalar(reduction_params)\ntopos = fc.reduce_to_topo(reduction_params)\n\n# Those are numpy arrays.\nprint('%i markers' % scalars.shape)\nprint('%i markers, %i channels' % topos.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot a few markers\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's create convenient names from the marker keys.\nto_plot = ['nice/marker/PowerSpectralDensity/deltan',\n           'nice/marker/PowerSpectralDensity/thetan',\n           'nice/marker/PowerSpectralDensity/alphan',\n           'nice/marker/PowerSpectralDensity/betan',\n           'nice/marker/PowerSpectralDensity/gamman']\n\nidx = [list(fc.keys()).index(x) for x in to_plot]\nnames = [x.split('/')[-1] for x in to_plot]\ntopos_to_plot = topos[idx]\n\n\n# Prepare fancy EGI plot with nicer outline.\nmontage = mne.channels.read_montage('GSN-HydroCel-256')\nch_names = ['E{}'.format(i) for i in range(1, 257)]\ninfo = mne.create_info(ch_names, 1, ch_types='eeg', montage=montage)\nlayout = mne.channels.make_eeg_layout(info)\npos = layout.pos[:, :2]\n\n_egi256_outlines = {\n    'ear1': np.array([190, 191, 201, 209, 218, 217, 216, 208, 200, 190]),\n    'ear2': np.array([81, 72, 66, 67, 68, 73, 82, 92, 91, 81]),\n    'outer': np.array([9, 17, 24, 30, 31, 36, 45, 243, 240, 241, 242, 246, 250,\n                       255, 90, 101, 110, 119, 132, 144, 164, 173, 186, 198,\n                       207, 215, 228, 232, 236, 239, 238, 237, 233, 9]),\n}\n\noutlines = {}\ncodes = []\nvertices = []\n\nfor k, v in _egi256_outlines.items():\n    t_verts = pos[v, :]\n    outlines[k] = (t_verts[:, 0], t_verts[:, 1])\n    t_codes = 2 * np.ones(v.shape[0])\n    t_codes[0] = 1\n    codes.append(t_codes)\n    vertices.append(t_verts)\nvertices = np.concatenate(vertices, axis=0)\ncodes = np.concatenate(codes, axis=0)\n\npath = Path(vertices=vertices, codes=codes)\n\n\ndef patch():  # noqa\n    return PathPatch(path, color='white', alpha=0.1)\n\n\noutlines['mask_pos'] = outlines['outer']\noutlines['patch'] = patch\npos = layout.pos[:, :2]\nmask = np.in1d(np.arange(len(pos)), scalp_roi)\nmask_params = dict(marker='+', markerfacecolor='k', markeredgecolor='k',\n                   linewidth=0, markersize=1)\n\ncmap = 'viridis'\nn_axes = len(names)\n\nfig_kwargs = dict(figsize=(3 * n_axes, 4))\nfig, axes = plt.subplots(1, n_axes, **fig_kwargs)\n\nfor ax, name, topo in zip(axes, names, topos_to_plot):\n    vmin = np.nanmin(topo[scalp_roi])\n    vmax = np.nanmax(topo[scalp_roi])\n    topo[non_scalp] = vmin\n    nan_idx = np.isnan(topo)\n\n    im, _ = mne.viz.topomap.plot_topomap(\n        topo[~nan_idx], pos[~nan_idx], vmin=vmin, vmax=vmax, axes=ax,\n        cmap=cmap, image_interp='nearest', outlines=outlines, sensors=False,\n        mask=mask, mask_params=mask_params, contours=0)\n\n    ax.set_title(name)\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    cbar = plt.colorbar(im, cax=cax, ticks=(vmin, vmax))\n    cbar.ax.tick_params(labelsize=8)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}